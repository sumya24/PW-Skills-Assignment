{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32db4652-875e-4dd6-a00a-9d5f888e442a",
   "metadata": {},
   "source": [
    "## Q1. Describe the decision tree classifier algorithm and how it works to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc38ee9-d4f8-4961-8155-a8c980baddba",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "A Decision Tree Classifier is a supervised learning algorithm used for classification problems. It splits the dataset into smaller subsets based on feature values using decision rules in the form of tree branches.\n",
    "\n",
    "The tree starts at a root node and splits the data based on the feature that provides the best separation using a metric like Gini Index or Entropy.\n",
    "\n",
    "The splitting continues recursively to create branches and leaf nodes, where each leaf node represents a class label.\n",
    "\n",
    "To make a prediction, the input instance traverses the tree from root to leaf by following decision rules until it reaches a final class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858e9db7-3b64-45a9-b8d7-f87c935c79af",
   "metadata": {},
   "source": [
    "## Q2. Provide a step-by-step explanation of the mathematical intuition behind decision tree classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643f2c32-5c0b-43de-a9a2-81651fb0d2ce",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Choose a feature to split the data. Use one of the following metrics:\n",
    "\n",
    "Gini Index:\n",
    "Gini = 1 - ∑ (pᵢ²), where pᵢ is the probability of class i\n",
    "\n",
    "Entropy (Information Gain):\n",
    "Entropy = -∑ (pᵢ * log₂(pᵢ))\n",
    "\n",
    "Calculate the metric for each feature and select the one that gives the best split (lowest Gini or highest Info Gain).\n",
    "\n",
    "Split the dataset into subsets based on the best feature.\n",
    "\n",
    "Repeat the process recursively for each subset until one of the stopping conditions is met:\n",
    "\n",
    "All instances belong to the same class\n",
    "\n",
    "No features left\n",
    "\n",
    "Tree reaches a pre-defined depth\n",
    "\n",
    "Assign a label to the leaf nodes based on the majority class in the subset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c17bfdb-ae15-451b-837a-5d5d3d585387",
   "metadata": {},
   "source": [
    "## Q3. Explain how a decision tree classifier can be used to solve a binary classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36d323c-b9f3-41d9-a40d-642baa9fa820",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "In binary classification, a decision tree:\n",
    "\n",
    "Starts by selecting the best feature to split the dataset into two groups (yes/no or 0/1).\n",
    "\n",
    "Continues splitting each subset into further branches based on feature thresholds.\n",
    "\n",
    "At each leaf node, the majority class is assigned (0 or 1).\n",
    "\n",
    "For a new data point, the tree is traversed based on its feature values, and the model predicts either Class 0 or Class 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86a8322-eda0-4234-bc3b-4d3be8725401",
   "metadata": {},
   "source": [
    "## Q4. Discuss the geometric intuition behind decision tree classification and how it can be used to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e36319-3148-4e1b-83ff-3aef1f47cfeb",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Geometrically, a decision tree creates axis-aligned splits in the feature space.\n",
    "\n",
    "Each decision rule corresponds to a line (2D) or plane (3D) that divides the space.\n",
    "\n",
    "As you go deeper in the tree, the model partitions the space into smaller rectangles (regions).\n",
    "\n",
    "Each region corresponds to a specific class label.\n",
    "\n",
    "To predict a new sample, the model checks which region the sample falls into and assigns the class of that region."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d366927-d159-40aa-8b9e-8bf8fecc3019",
   "metadata": {},
   "source": [
    "## Q5. Define the confusion matrix and describe how it can be used to evaluate the performance of a classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd28a9f-dc4e-4f2c-9383-63003f2dd2a4",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "A Confusion Matrix is a table used to evaluate the performance of a classification model. For binary classification, it has 4 components:It helps calculate important metrics like Accuracy, Precision, Recall, and F1-Score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf8dd2f-7c99-4e8b-89db-3b6f7409855d",
   "metadata": {},
   "source": [
    "Q6. Provide an example of a confusion matrix and explain how precision, recall, and F1 score can be calculated from it.\n",
    "Precision = TP / (TP + FP) = 80 / (80 + 10) = 0.888\n",
    "\n",
    "Recall = TP / (TP + FN) = 80 / (80 + 20) = 0.8\n",
    "\n",
    "F1 Score = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "= 2 * (0.888 * 0.8) / (0.888 + 0.8) ≈ 0.842"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b60770-e5c4-4757-9962-5f755236cb5e",
   "metadata": {},
   "source": [
    "## Q7. Discuss the importance of choosing an appropriate evaluation metric for a classification problem and explain how this can be done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4700c70b-3ba0-47f0-8301-928e74845a13",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Choosing the right metric is important because different problems have different goals:\n",
    "\n",
    "Accuracy may be misleading on imbalanced data.\n",
    "\n",
    "Precision is important when false positives are costly.\n",
    "\n",
    "Recall is important when false negatives are costly.\n",
    "\n",
    "F1 Score is a balanced metric for imbalanced datasets.\n",
    "\n",
    "ROC-AUC is useful for evaluating across thresholds.\n",
    "\n",
    "How to choose:\n",
    "\n",
    "Understand the business context.\n",
    "\n",
    "Analyze the impact of false positives vs. false negatives.\n",
    "\n",
    "Use multiple metrics to get a complete view."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa006ad-8d05-4174-a424-7d1e250cf093",
   "metadata": {},
   "source": [
    "## Q8. Provide an example of a classification problem where precision is the most important metric, and explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ba7aec-53e9-4fca-920a-2bbfea1f9125",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Example: Spam detection in emails\n",
    "\n",
    "Precision is crucial because we don’t want to wrongly classify an important email as spam (false positive).\n",
    "\n",
    "It's better to let a few spam emails through (false negatives) than to lose a genuine email."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3a3921-3fe1-462a-88eb-cbc653f87ad9",
   "metadata": {},
   "source": [
    "## Q9. Provide an example of a classification problem where recall is the most important metric, and explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538d1eff-33f6-4b33-9768-53ad64a13053",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Example: Cancer detection in medical diagnosis\n",
    "\n",
    "Recall is crucial because missing a positive case (false negative) can lead to serious consequences.\n",
    "\n",
    "It's better to flag all possible cancer cases (even some false alarms) than to miss a patient who actually has cancer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6445e49c-5fbd-42b1-8eb8-6934c5818bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
