{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b45d404-232b-4b0c-94e0-911d2c351f48",
   "metadata": {},
   "source": [
    "## Q1. What is Web Scraping? Why is it used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af44aad-cbd5-4098-a84b-b004bbaf723c",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Web Scraping is a technique used to automatically extract data from websites using code. It involves fetching the HTML of a webpage and then parsing it to find useful information.\n",
    "\n",
    "Why it is used:\n",
    "\n",
    "To collect large amounts of data from websites quickly and automatically.\n",
    "\n",
    "Helps in data analysis, price tracking, research, and automation.\n",
    "\n",
    "Three areas where Web Scraping is used:\n",
    "\n",
    "E-commerce – To compare prices of products across different platforms.\n",
    "\n",
    "Job Portals – To collect job postings and trends from job listing websites.\n",
    "\n",
    "News and Media – To gather the latest headlines and articles for sentiment analysis or news aggregation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd8eb1d-c2f1-476b-95ae-1a8249d63c8c",
   "metadata": {},
   "source": [
    "## Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35276ea2-53a2-4662-8081-5dcaf4a124df",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "There are multiple ways to perform web scraping:\n",
    "\n",
    "Using built-in libraries like:\n",
    "\n",
    "urllib\n",
    "\n",
    "http.client\n",
    "\n",
    "requests\n",
    "\n",
    "Using parsing libraries like:\n",
    "\n",
    "BeautifulSoup\n",
    "\n",
    "lxml\n",
    "\n",
    "html.parser\n",
    "\n",
    "Using browser automation tools like:\n",
    "\n",
    "Selenium (used when websites load content dynamically using JavaScript)\n",
    "\n",
    "Using Web Scraping Frameworks like:\n",
    "\n",
    "Scrapy – a powerful and scalable web scraping framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cdb33e-84e6-49d5-8036-b711708ad2b0",
   "metadata": {},
   "source": [
    "## Q3. What is BeautifulSoup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb84ec66-0c8c-4799-96be-0d07625e3347",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "BeautifulSoup is a Python library used to parse HTML and XML documents. It creates a parse tree from the page source code, making it easy to search, navigate, and modify the HTML content.\n",
    "\n",
    "Why it is used:\n",
    "\n",
    "It simplifies the process of extracting data from web pages.\n",
    "\n",
    "Helps find tags, attributes, and text easily using functions like find(), find_all(), etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69afe58c-292b-442a-9de7-1208c62705f9",
   "metadata": {},
   "source": [
    "## Q4. Why is Flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b185056-363b-4fb0-ae90-0df30c48f3fe",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Flask is a lightweight Python web framework. It is used in web scraping projects to:\n",
    "\n",
    "Create a web interface for users to enter input (like keywords or URLs).\n",
    "\n",
    "Run scraping code in the backend and return results.\n",
    "\n",
    "Display scraped data on a web page or allow it to be downloaded.\n",
    "\n",
    "Example use-case: You can create a form in Flask that takes a search query, scrapes data from a website, and displays the result in your browser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a1cfe5-ea1f-421f-b937-e2f083f73bfe",
   "metadata": {},
   "source": [
    "## Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dd8db8-6d0c-4c73-ad71-93642ef85e01",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Here are common AWS services used in a Web Scraping project:\n",
    "\n",
    "EC2 (Elastic Compute Cloud)\n",
    "\n",
    "Used to host the web scraping app (e.g., your Flask app).\n",
    "\n",
    "You can run Python scripts and host web servers on virtual machines (instances).\n",
    "\n",
    "S3 (Simple Storage Service)\n",
    "\n",
    "Used to store the scraped data like CSV, Excel files, or logs.\n",
    "\n",
    "Great for long-term and scalable storage.\n",
    "\n",
    "Lambda (Optional)\n",
    "\n",
    "Used to run scraping code without managing a server, especially if scraping is done on a schedule.\n",
    "\n",
    "CloudWatch\n",
    "\n",
    "Used for monitoring logs and errors during web scraping.\n",
    "\n",
    "Helps you track performance and failures.\n",
    "\n",
    "IAM (Identity and Access Management)\n",
    "\n",
    "Used to manage secure access to AWS services and resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c311ae-9415-4ecd-8bda-7926b5e963a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
