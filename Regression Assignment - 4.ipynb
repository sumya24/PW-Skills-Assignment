{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80aac4fe-92fe-43a2-9953-a7e1ffebddf4",
   "metadata": {},
   "source": [
    "## Q1. What is Lasso Regression, and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe1dace-a8cd-41b6-804d-6cbed0891d44",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Lasso Regression (Least Absolute Shrinkage and Selection Operator) is a type of linear regression that uses L1 regularization to shrink model coefficients. It adds a penalty equal to the absolute value of the coefficients to the loss function:\n",
    "\n",
    "How it differs from other techniques:\n",
    "\n",
    "Unlike Ordinary Least Squares (OLS), Lasso prevents overfitting by adding a regularization term.\n",
    "\n",
    "Unlike Ridge Regression, which uses L2 penalty and only shrinks coefficients, Lasso can shrink some coefficients to zero, eliminating unimportant features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99de7825-7d6f-4620-a5af-5c8921ac642f",
   "metadata": {},
   "source": [
    "## Q2. What is the main advantage of using Lasso Regression in feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c468cd-5546-40d4-8253-c83f0eea2570",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "The main advantage of Lasso Regression in feature selection is its ability to automatically reduce irrelevant or less important feature coefficients to zero. This means it can select a subset of useful features, which:\n",
    "\n",
    "Simplifies the model,\n",
    "\n",
    "Improves interpretability,\n",
    "\n",
    "Reduces the risk of overfitting,\n",
    "\n",
    "Helps when there are more features than observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d69caea-8321-446c-a750-cdc9fbe51763",
   "metadata": {},
   "source": [
    "## Q3. How do you interpret the coefficients of a Lasso Regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f6fe3e-d985-4e17-b393-eac731a8a5a7",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "The interpretation of Lasso Regression coefficients is similar to linear regression — each coefficient represents the expected change in the target variable for a unit change in the corresponding feature, assuming other features are constant.\n",
    "\n",
    "However, due to L1 regularization:\n",
    "\n",
    "Some coefficients may be exactly zero, indicating that those features are not useful for the model.\n",
    "\n",
    "Remaining non-zero coefficients are shrunken, so the values may be smaller than in ordinary least squares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2532b31f-21f0-4d50-b20d-09783df133ae",
   "metadata": {},
   "source": [
    "## Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d3f720-cfe6-40de-a9cd-e7533bfcfada",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "The main tuning parameter in Lasso Regression is lambda (α), the regularization parameter that controls the strength of the L1 penalty.\n",
    "\n",
    "Higher lambda values apply more penalty, shrinking more coefficients to zero, possibly leading to underfitting.\n",
    "\n",
    "Lower lambda values apply less penalty, resulting in a model closer to OLS, possibly leading to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3cb51e-731b-4975-814e-5ffc29e22a93",
   "metadata": {},
   "source": [
    "## Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dd2a93-51d0-4006-b87d-68d0dc4dade2",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Yes, Lasso Regression can be adapted for non-linear regression problems by using feature transformation techniques such as:\n",
    "\n",
    "Polynomial features: Transform the original input features into higher-degree terms and then apply Lasso.\n",
    "\n",
    "Interaction terms: Combine features  and use Lasso for regularized modeling.\n",
    "\n",
    "Kernel trick: Use kernel methods (like in SVMs) to project data into a higher-dimensional space, followed by Lasso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3c8a94-f3b9-412d-9568-18fcdf24ab0b",
   "metadata": {},
   "source": [
    "## Q6. What is the difference between Ridge Regression and Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a30889-8252-4999-93c9-a85a651b9ab7",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "The main difference lies in the type of regularization:\n",
    "\n",
    "Ridge Regression uses L2 regularization, adding the square of the coefficients to the loss function. It shrinks coefficients but doesn’t eliminate any.\n",
    "\n",
    "Lasso Regression uses L1 regularization, adding the absolute value of coefficients. It can shrink some coefficients to zero, effectively selecting features.\n",
    "\n",
    "Therefore:\n",
    "\n",
    "Ridge is better when all features are useful but correlated.\n",
    "\n",
    "Lasso is better when some features are irrelevant or redundant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a4a506-c0cd-42bf-b3bd-a9e28127a6e3",
   "metadata": {},
   "source": [
    "## Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a8992d-bb8c-404f-9982-2e37f71ea155",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Yes, Lasso Regression can handle multicollinearity to some extent. When predictors are highly correlated:\n",
    "\n",
    "Lasso tends to select only one of the correlated features and sets the others to zero.\n",
    "\n",
    "This helps to reduce model complexity and improve generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6328580a-994a-4503-ad67-f1fbc5d36d80",
   "metadata": {},
   "source": [
    "## Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31313859-7ee2-4e5c-bd5b-9eacf3e8af51",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "To choose the optimal lambda value in Lasso Regression, use:\n",
    "\n",
    "Cross-validation (CV), such as K-Fold CV, to evaluate the model's performance across a range of lambda values.\n",
    "\n",
    "Select the lambda that minimizes the cross-validation error or validation RMSE.\n",
    "\n",
    "Tools like LassoCV in scikit-learn automate this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430dc040-6794-4fb5-8346-3b0453c4e2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
